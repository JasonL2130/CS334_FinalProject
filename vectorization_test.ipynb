{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data_raw = pd.read_csv('/Users/JasonLebov_1/Desktop/CS 334/Final Project/Final Project Data/fraud test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data_raw['first'] = fraud_data_raw['first'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = list(fraud_data_raw['first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_names = [\n",
    "    \"james\", \"john\", \"robert\", \"michael\", \"william\", \"david\", \"richard\", \"joseph\", \"charles\", \"thomas\", \"jinhoi\", 'carl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=[first_names], vector_size=50, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_emb = {name: model.wv[name] for name in first_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "james: [ 0.0054912  -0.01672126  0.01571909  0.01707281 -0.01917442  0.00488685\n",
      "  0.01981204 -0.01533455 -0.01392801 -0.01547779  0.01679487 -0.0013612\n",
      "  0.01828159 -0.01631789  0.00748043  0.00527541  0.00148549  0.00464907\n",
      " -0.01493154 -0.01870942  0.00471235  0.01230033  0.01597448  0.01148025\n",
      " -0.00156003  0.01661636 -0.01868086  0.00681     0.00054124  0.0077085\n",
      "  0.01476373 -0.01344592  0.01117614 -0.01904451 -0.00160393 -0.01737867\n",
      " -0.01019501  0.01857459 -0.00371937  0.00582743  0.01814771  0.01787352\n",
      " -0.01641449 -0.00603224  0.01977037  0.01020402 -0.00317471 -0.0173813\n",
      "  0.00592467 -0.01334943]\n",
      "john: [-1.7454965e-02  4.2603230e-03 -1.7470884e-03 -1.8638177e-02\n",
      " -1.8856285e-02 -2.8214359e-03  8.8648172e-03  7.4081421e-03\n",
      " -1.2997386e-02 -1.3746135e-02 -9.9988244e-03 -4.5736884e-03\n",
      " -1.4500575e-02 -1.9206636e-02 -5.4872585e-03 -1.6725682e-02\n",
      " -1.2077752e-02 -1.1341858e-02 -4.6882750e-03 -3.4139943e-03\n",
      " -1.7913997e-02 -1.4703989e-03  1.6305013e-02  1.5380859e-02\n",
      " -1.4412232e-02 -7.3336624e-03  6.2371041e-03 -1.9141445e-02\n",
      "  2.9528784e-03  1.3048933e-02  1.1492839e-02 -1.7526124e-02\n",
      " -9.0342881e-03 -1.6280321e-02  9.1912749e-05  1.8527268e-02\n",
      "  1.1946611e-02  1.0134616e-02  1.0122125e-02 -6.4858343e-03\n",
      "  1.9104367e-02 -1.4712849e-02 -1.4540775e-02 -4.5307782e-03\n",
      " -1.5571213e-03 -6.4322068e-03 -1.1851717e-03  1.4977646e-02\n",
      " -1.3950372e-03 -3.2498813e-03]\n",
      "robert: [ 0.00805774  0.00869293  0.01991022 -0.00895007 -0.00277909 -0.01463072\n",
      " -0.01939346 -0.01815512 -0.00204584 -0.01300446  0.0096961  -0.01232638\n",
      "  0.00504176  0.00147723 -0.00678019 -0.00196021  0.01996173  0.01829528\n",
      " -0.00892433  0.01816388 -0.0112845   0.01185701 -0.0061942   0.00686681\n",
      "  0.0060354   0.01379645 -0.00474971  0.01755309  0.01517718 -0.01909501\n",
      " -0.01601985 -0.01527458  0.00584775 -0.00559113 -0.01386136 -0.01625862\n",
      "  0.01662145  0.0039806  -0.01865587 -0.00959027  0.00627015 -0.00942695\n",
      "  0.010562   -0.00846858  0.00528696 -0.01608991  0.01242377  0.00963413\n",
      "  0.00156978  0.00602624]\n",
      "michael: [-0.01427803  0.00248206 -0.01435343 -0.00448924  0.00743861  0.01166625\n",
      "  0.00239637  0.00420546 -0.00822078  0.01445067 -0.01261408  0.00929443\n",
      " -0.01643995  0.00407294 -0.0099541  -0.00849538 -0.00621797  0.01131042\n",
      "  0.0115968  -0.0099493   0.00154666 -0.01699156  0.01561961  0.01851458\n",
      " -0.00548466  0.00160045  0.0014933   0.01095577 -0.01721216  0.00116891\n",
      "  0.01373884  0.00446319  0.00224935 -0.01864431  0.01696473 -0.01252825\n",
      " -0.00598475  0.00698757 -0.00154526  0.00282258  0.00356398 -0.0136578\n",
      " -0.01944962  0.01808117  0.01239611 -0.01382586  0.00680696  0.00041213\n",
      "  0.00950749 -0.01423989]\n",
      "william: [ 0.00855799  0.00014501 -0.01917313 -0.01932753 -0.01229587 -0.00024605\n",
      "  0.00400302  0.01886975  0.01116242 -0.00857491  0.00055062  0.00993035\n",
      "  0.01540213 -0.00229358  0.00865533 -0.01162868 -0.00160275  0.01620208\n",
      " -0.00472209 -0.01933143  0.01155481 -0.00786723 -0.00244188  0.01996219\n",
      " -0.00450978 -0.00952016 -0.01066107  0.01396333 -0.01142039  0.00423057\n",
      " -0.01051063  0.01223969  0.00871489  0.00520561 -0.00298534 -0.0054955\n",
      "  0.01798357  0.01043052 -0.00432166 -0.01894315 -0.01485335 -0.00212404\n",
      " -0.00159261 -0.00512699  0.01936951 -0.00090998  0.01175043 -0.01490235\n",
      " -0.0050197  -0.0111008 ]\n",
      "david: [-0.01648536  0.01859871 -0.00039532 -0.00393455  0.00920726 -0.00819063\n",
      "  0.00548623  0.01387993  0.01213085 -0.01502159  0.0187647   0.00934362\n",
      "  0.00793224 -0.01248701  0.01691996 -0.00430033  0.01765038 -0.01072401\n",
      " -0.01625884  0.01364912  0.00334239 -0.00439702  0.0190272   0.01898771\n",
      " -0.01954809  0.00501046  0.01231338  0.00774491  0.00404557  0.000861\n",
      "  0.00134726 -0.00764127 -0.0142805  -0.00417774  0.0078478   0.01763737\n",
      "  0.0185183  -0.01195187 -0.01880534  0.01952875  0.00685957  0.01033223\n",
      "  0.01256469 -0.00560853  0.01464541  0.00566054  0.00574201 -0.00476074\n",
      " -0.0062565  -0.00474028]\n",
      "richard: [ 2.8740549e-03 -5.2920175e-03 -1.4147566e-02 -1.5610614e-02\n",
      " -1.8243574e-02 -1.1870339e-02 -3.6948491e-03 -8.6477427e-03\n",
      " -1.2921341e-02 -7.4346447e-03  8.5783172e-03 -7.4780867e-03\n",
      "  1.6756350e-02  3.0679870e-03 -1.4484639e-02  1.8867597e-02\n",
      "  1.5262425e-02  1.0986564e-02 -1.3697691e-02  1.1645358e-02\n",
      "  8.0181863e-03  1.0370739e-02  8.5118031e-03  3.8795089e-03\n",
      " -6.3403249e-03  1.6707690e-02  1.9224361e-02  7.5852061e-03\n",
      " -5.6739901e-03  1.4255047e-05  2.4376370e-03 -1.6916649e-02\n",
      " -1.6447891e-02 -4.6203137e-04  2.4745751e-03 -1.1486761e-02\n",
      " -9.4505474e-03 -1.4692149e-02  1.6657231e-02  2.4259568e-04\n",
      " -9.0187974e-03  1.1403411e-02  1.8360030e-02 -8.1997439e-03\n",
      "  1.5929364e-02  1.0750868e-02  1.1758246e-02  1.0251808e-03\n",
      "  1.6426168e-02 -1.4038081e-02]\n",
      "joseph: [ 0.00018921  0.00615743 -0.01363147 -0.00275218  0.01534412  0.01469949\n",
      " -0.00734993  0.0052878  -0.01664181  0.0124166  -0.00927885 -0.00633109\n",
      "  0.01863117  0.00174756  0.01498821 -0.01215364  0.0103257   0.01985465\n",
      " -0.01692246 -0.01027604 -0.01413609 -0.00972972 -0.00756056 -0.01708015\n",
      "  0.01591843 -0.00969227  0.01685487  0.01052992 -0.013106    0.00791934\n",
      "  0.01094527 -0.01485981 -0.01481816 -0.00495271 -0.01725928 -0.00316458\n",
      " -0.00080723  0.00660236  0.00288507 -0.00176364 -0.01119319  0.0034623\n",
      " -0.00179556  0.01359355  0.00795079  0.00906305  0.00286991 -0.00540216\n",
      " -0.00873759 -0.00206509]\n",
      "charles: [ 1.56352110e-02 -1.90174002e-02 -4.17757896e-04  6.93708006e-03\n",
      " -1.87046581e-03  1.67707428e-02  1.80180464e-02  1.30756414e-02\n",
      " -1.43133814e-03  1.54268919e-02 -1.70732159e-02  6.41116733e-03\n",
      " -9.26693808e-03 -1.01770638e-02  7.18655391e-03  1.07347677e-02\n",
      "  1.55439964e-02 -1.15234004e-02  1.48585094e-02  1.32459356e-02\n",
      " -7.42644956e-03 -1.74960550e-02  1.08712716e-02  1.30111752e-02\n",
      " -1.56736840e-03 -1.34244720e-02 -1.41636310e-02 -4.98904614e-03\n",
      "  1.02800811e-02 -7.32656289e-03 -1.87347438e-02  7.64629012e-03\n",
      "  9.76172648e-03 -1.28595214e-02  2.40875455e-03 -4.15124651e-03\n",
      "  4.83643598e-05 -1.97638161e-02  5.38546871e-03 -9.50104278e-03\n",
      "  2.16982490e-03 -3.15073552e-03  4.39244043e-03 -1.57565083e-02\n",
      " -5.43051260e-03  5.33085736e-03  1.06947245e-02 -4.78568813e-03\n",
      " -1.90244466e-02  9.01073404e-03]\n",
      "thomas: [-0.01723938  0.00733148  0.01037977  0.01148388  0.01493384 -0.01233535\n",
      "  0.00221123  0.01209456 -0.0056801  -0.01234705 -0.00082045 -0.0167379\n",
      " -0.01120002  0.01420908  0.00670508  0.01445134  0.01360049  0.01506148\n",
      " -0.00757831 -0.00112361  0.00469675 -0.00903806  0.01677746 -0.01971633\n",
      "  0.01352928  0.00582883 -0.00986566  0.00879638 -0.00347915  0.01342277\n",
      "  0.0199297  -0.00872489 -0.00119868 -0.01139127  0.00770164  0.00557325\n",
      "  0.01378215  0.01220219  0.01907699  0.01854683  0.01579614 -0.01397901\n",
      " -0.01831173 -0.00071151 -0.00619968  0.01578863  0.01187715 -0.00309133\n",
      "  0.00302193  0.00358008]\n",
      "jinhoi: [-0.01631419  0.00899381 -0.00827529  0.00164591  0.01700149 -0.00892238\n",
      "  0.00903024 -0.0135749  -0.00709913  0.01879944 -0.00315811  0.00064046\n",
      " -0.00827811 -0.01536517 -0.00301375  0.00493754 -0.0017711   0.01107252\n",
      " -0.00548792  0.00452326  0.01090615  0.01668975 -0.00291068 -0.01841851\n",
      "  0.00874418  0.00114252  0.01488662 -0.00162345 -0.00527594 -0.0175075\n",
      " -0.00171418  0.00564951  0.01079988  0.01410476 -0.01141082  0.00371576\n",
      "  0.01217953 -0.00959566 -0.00621607  0.01359337  0.00326191  0.00037762\n",
      "  0.00695031  0.00043689  0.01923854  0.01012045 -0.01783113 -0.01408312\n",
      "  0.00179981  0.01278569]\n",
      "carl: [-1.06885051e-03  4.70424158e-04  1.02043748e-02  1.80174410e-02\n",
      " -1.86079666e-02 -1.42302141e-02  1.29204988e-02  1.79485716e-02\n",
      " -1.00328270e-02 -7.52690295e-03  1.47602400e-02 -3.06617282e-03\n",
      " -9.06765554e-03  1.31054400e-02 -9.71600972e-03 -3.63371754e-03\n",
      "  5.75650623e-03  1.98846427e-03 -1.65734831e-02 -1.89016555e-02\n",
      "  1.46228569e-02  1.01380600e-02  1.35165285e-02  1.52917928e-03\n",
      "  1.27029587e-02 -6.81254966e-03 -1.89566670e-03  1.15412232e-02\n",
      " -1.50449919e-02 -7.87120778e-03 -1.50242774e-02 -1.86117541e-03\n",
      "  1.90779381e-02 -1.46414805e-02 -4.67045652e-03 -3.87930614e-03\n",
      "  1.61569547e-02 -1.18594524e-02  8.96020647e-05 -9.51112527e-03\n",
      " -1.92084499e-02  1.00158295e-02 -1.75204519e-02 -8.78514629e-03\n",
      " -6.48260611e-05 -5.90393553e-04 -1.53192701e-02  1.92247964e-02\n",
      "  9.96108074e-03  1.84641872e-02]\n"
     ]
    }
   ],
   "source": [
    "for name, embedding in name_emb.items():\n",
    "    print(f\"{name}: {embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name     dim_1     dim_2     dim_3     dim_4     dim_5     dim_6  \\\n",
      "0     james  0.035808  0.051797 -0.038422  0.049586  0.044187 -0.024737   \n",
      "1      john  0.052117 -0.063401 -0.001370  0.023128 -0.006260  0.055878   \n",
      "2    robert  0.018569  0.045935  0.040687  0.063587  0.061825  0.052648   \n",
      "3   michael  0.015656 -0.030127  0.055925 -0.065721  0.045098  0.019429   \n",
      "4   william -0.041120  0.007360  0.040319 -0.018938 -0.041143 -0.002755   \n",
      "5     david  0.010877  0.001266  0.023158  0.001452  0.064126  0.033737   \n",
      "6   richard  0.003812  0.049613 -0.005422 -0.017589 -0.058353 -0.005710   \n",
      "7    joseph -0.010522  0.002143 -0.027617 -0.051241 -0.010058  0.016473   \n",
      "8   charles -0.001980 -0.051074  0.064085  0.033189  0.061549 -0.054378   \n",
      "9    thomas -0.050077 -0.006200  0.063587 -0.048794 -0.015558 -0.012918   \n",
      "10   jinhoi -0.012108  0.019179  0.006616 -0.055240 -0.062982  0.048756   \n",
      "11     carl -0.003578  0.001579  0.034029  0.060063 -0.062014 -0.047450   \n",
      "\n",
      "       dim_7     dim_8     dim_9    dim_10    dim_11    dim_12    dim_13  \\\n",
      "0  -0.058305  0.036226  0.043405 -0.005253 -0.044742 -0.047253 -0.016649   \n",
      "1   0.060072  0.043577 -0.004744  0.051403 -0.056896  0.021381 -0.030920   \n",
      "2  -0.046603 -0.061046 -0.002365 -0.020652  0.052637  0.039609 -0.010304   \n",
      "3  -0.032886  0.029321 -0.011597  0.044743  0.066432 -0.029083 -0.003996   \n",
      "4  -0.055793 -0.037322  0.047369  0.022374  0.048164  0.045351  0.050190   \n",
      "5  -0.059449 -0.046944  0.006010  0.042617 -0.057465  0.024438  0.034599   \n",
      "6   0.018844  0.036010  0.047018 -0.038021  0.012392  0.040592 -0.031987   \n",
      "7  -0.005923  0.036908 -0.018295  0.015074  0.036388  0.055665 -0.009696   \n",
      "8   0.029969 -0.027562  0.005488  0.056665 -0.029730  0.030144 -0.045251   \n",
      "9   0.053850 -0.039539  0.000301 -0.031692 -0.064024  0.033382 -0.058397   \n",
      "10  0.033797  0.045044  0.005082  0.042343 -0.022690 -0.006289  0.038454   \n",
      "11  0.043046  0.059818 -0.033427 -0.025080  0.049209 -0.010210 -0.030244   \n",
      "\n",
      "      dim_14    dim_15  \n",
      "0   0.034310 -0.024438  \n",
      "1  -0.033926  0.023931  \n",
      "2   0.010058  0.011946  \n",
      "3  -0.037971  0.025672  \n",
      "4  -0.025282 -0.003724  \n",
      "5   0.038280  0.049779  \n",
      "6  -0.020715  0.045318  \n",
      "7  -0.061415  0.029150  \n",
      "8  -0.023687  0.062671  \n",
      "9  -0.029279 -0.000234  \n",
      "10 -0.050159 -0.026228  \n",
      "11  0.043684 -0.032394  \n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec model on the list of names\n",
    "model = Word2Vec(sentences=[first_names], vector_size=15, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Initialize an empty DataFrame to store embeddings\n",
    "embedding_df = pd.DataFrame(columns=[f\"dim_{i}\" for i in range(1, 16)])\n",
    "\n",
    "# Iterate through each name in the original list\n",
    "for name in first_names:\n",
    "    # Generate Word2Vec embedding for the current name\n",
    "    embedding = model.wv[name]\n",
    "    # Convert embedding to DataFrame row and append to embedding_df\n",
    "    embedding_series = pd.Series(embedding, index=embedding_df.columns, name=name)\n",
    "    embedding_df = pd.concat([embedding_df, embedding_series.to_frame().T])\n",
    "    \n",
    "# Reset index to have 'name' as a regular column\n",
    "embedding_df.reset_index(inplace=True)\n",
    "embedding_df.rename(columns={'index': 'name'}, inplace=True)\n",
    "\n",
    "# Now, embedding_df contains the Word2Vec embeddings for every name in the original list\n",
    "# You can use this DataFrame as input features for your machine learning model\n",
    "print(embedding_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
